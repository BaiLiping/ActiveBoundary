{"agent": "ppo", "states": {"type": "float", "shape": [4], "min_value": [-4.800000190734863, -Infinity, -0.41887903213500977, -Infinity], "max_value": [4.800000190734863, Infinity, 0.41887903213500977, Infinity]}, "actions": {"type": "int", "shape": [], "num_values": 2}, "max_episode_timesteps": 500, "batch_size": 64, "network": {"type": "auto", "rnn": false}, "use_beta_distribution": false, "memory": "minimum", "update_frequency": 1, "learning_rate": 0.001813150053725916, "subsampling_fraction": 0.9131375430837279, "optimization_steps": null, "likelihood_ratio_clipping": 0.09955676846552193, "discount": 0.9985351346308641, "predict_terminal_values": false, "baseline": {"type": "auto", "rnn": false}, "baseline_optimizer": {"optimizer": "adam", "learning_rate": 0.003670157218888348, "multi_step": 10}, "state_preprocessing": "linear_normalization", "reward_preprocessing": null, "exploration": 0.0, "variable_noise": 0.0, "l2_regularization": 0.0, "entropy_regularization": 0.0011393096635237982, "parallel_interactions": 1, "config": null, "saver": null, "summarizer": null, "recorder": null, "internals": {}, "initial_internals": {"policy": {}, "baseline": {}}}